"""
YOLOv11 ì•™ìƒë¸” ëª¨ë¸ ê¸°ë°˜ ìµœì¢… ì œì¶œ(Submission) ìƒì„± ìŠ¤í¬ë¦½íŠ¸

[ìµœì í™” ë¦¬í¬íŠ¸ - Public Score: 0.98930]
1. ê²€ì¶œ ì „ëµ (Detection Strategy):
    - Model A (Original): CONF 0.7 ì ìš©. ê³ ì‹ ë¢°ë„ ê°ì²´ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ê²€ì¶œ.
    - Model B (Enhanced): CONF 0.4 ì ìš©. CLAHE+Sharpening ì „ì²˜ë¦¬ë¥¼ í†µí•´ ì €í™”ì§ˆ ì´ë¯¸ì§€ì˜ ë¯¸íƒ(FN) ë³´ì™„.
2. ë°•ìŠ¤ ë³‘í•© ì „ëµ (WBF Fusion):
    - IoU Threshold 0.6: ì•Œì•½ì´ ë°€ì§‘ëœ í™˜ê²½ì—ì„œ ë°•ìŠ¤ê°€ í•˜ë‚˜ë¡œ ë­‰ì¹˜ëŠ” í˜„ìƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì„ê³„ê°’ ìƒí–¥.
    - Weights [1.05, 1.0]: ê¸°ë³¸ ëª¨ë¸(A)ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì†Œí­ ìš°ì„ ì‹œí•¨.
    - Skip Box Threshold 0.05: ì €ì‹ ë¢°ë„ í›„ë³´êµ°ì„ ìµœëŒ€í•œ í¬í•¨í•˜ì—¬ WBF ì—°ì‚°ì˜ ê¸°ì—¬ë„ ìƒìŠ¹ ìœ ë„.
3. ìµœì¢… í•„í„°ë§:
    - ì•™ìƒë¸” ì´í›„ í•©ì‚° ì ìˆ˜ 0.4(FINAL_CONF_TH) ì´ìƒë§Œ ê¸°ë¡í•˜ì—¬ ìµœì¢… ì¬í˜„ìœ¨(Recall) ê·¹ëŒ€í™”.
"""

import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime
from ultralytics import YOLO
from ensemble_boxes import weighted_boxes_fusion
from tqdm import tqdm
from PIL import Image, ImageDraw, ImageFont

# =========================
# (1) ê²½ë¡œ ë° ì„¤ì •
# =========================
TEST_IMG_DIR = Path(r"E:\github\healtheat_vision\data\test_images")
CLASS_MAP_CSV = Path(r"E:\github\healtheat_vision\artifacts\class_map.csv")
MODEL_A_PATH = Path(r"E:\github\healtheat_vision\artifacts\models\yolo11s_full_train_v1_e150.pt")
MODEL_B_PATH = Path(r"E:\github\healtheat_vision\artifacts\models\yolo11s_ft_v1_enhanced.pt")

# ê²°ê³¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
TIME_STR = datetime.now().strftime('%y%m%d_%H%M%S')
OUT_DIR = Path(r"E:\github\healtheat_vision\submissions") / f"ensemble_{TIME_STR}"
VIZ_DIR = OUT_DIR / "viz"
OUT_DIR.mkdir(parents=True, exist_ok=True)
VIZ_DIR.mkdir(parents=True, exist_ok=True)

SUBMISSION_CSV = OUT_DIR / "submission.csv"


# ì•™ìƒë¸” í•˜ì´í¼íŒŒë¼ë¯¸í„°
CONF_TH_A = 0.7      # ëª¨ë¸ AëŠ” ì—„ê²©í•˜ê²Œ (ê³ ë“ì  ìœ„ì£¼)
CONF_TH_B = 0.4      # ëª¨ë¸ BëŠ” ë„ˆê·¸ëŸ½ê²Œ (Aê°€ ë†“ì¹œ ê²ƒ ìˆ˜ì§‘)
FINAL_CONF_TH = 0.4  # WBF ì´í›„ ìµœì¢…ì ìœ¼ë¡œ ë‚¨ê¸¸ ì ìˆ˜
WBF_IOU_TH = 0.6
WBF_SKIP_TH = 0.05  # (ëª¨ë¸ Bì˜ í›„ë³´ë¥¼ ì‚´ë¦¬ê¸° ìœ„í•´)
WBF_WEIGHTS = [1.05, 1.0] # ëª¨ë¸ Aì˜ ìœ„ì¹˜ ì‹ ë¢°ë„ë¥¼ 5% ë” ë†’ê²Œ í‰ê°€

# =========================
# (2) ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================

def apply_preprocessing(img_bgr):
    """ëª¨ë¸ Bë¥¼ ìœ„í•œ CLAHE + Sharpening"""
    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    img = cv2.merge((cl, a, b))
    img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)
    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
    img = cv2.filter2D(img, -1, kernel)
    return img

def load_class_map():
    df = pd.read_csv(CLASS_MAP_CSV)
    id_to_orig = {int(r.yolo_id): int(r.orig_id) for r in df.itertuples(index=False)}
    id_to_name = {int(r.yolo_id): str(r.class_name) for r in df.itertuples(index=False)}
    return id_to_orig, id_to_name

def draw_hangeul_label(img, text, position, font_path="malgun.ttf", font_size=18, color=(0, 255, 0)):
    """OpenCV ì´ë¯¸ì§€ì— PILì„ ì´ìš©í•´ í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜"""
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    try:
        font = ImageFont.truetype(font_path, font_size)
    except:
        font = ImageFont.load_default()
    
    # í…ìŠ¤íŠ¸ ë°°ê²½(ê²€ì€ìƒ‰)ì„ ì‚´ì§ ë„£ì–´ ê°€ë…ì„± í™•ë³´
    draw.text(position, text, font=font, fill=color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# =========================
# (3) ë©”ì¸ ì¶”ë¡  ë¡œì§
# =========================

def main():
    yolo_to_orig, yolo_to_name = load_class_map()
    model_a = YOLO(str(MODEL_A_PATH))
    model_b = YOLO(str(MODEL_B_PATH))
    
    img_paths = sorted(list(TEST_IMG_DIR.glob("*.png")) + list(TEST_IMG_DIR.glob("*.jpg")))
    rows = []
    ann_id = 1

    for img_path in tqdm(img_paths, desc="ì•™ìƒë¸” ì¶”ë¡  ì¤‘"):
        image_id = int(''.join(filter(str.isdigit, img_path.stem)))
        
        # ì´ë¯¸ì§€ ë¡œë“œ (í•œê¸€ ê²½ë¡œ ëŒ€ì‘)
        img_array = np.fromfile(str(img_path), np.uint8)
        img_bgr = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        if img_bgr is None: continue
        h, w = img_bgr.shape[:2]
        
        # 1. ëª¨ë¸ë³„ ì¶”ë¡ 
        res_a = model_a.predict(img_bgr, conf=CONF_TH_A, verbose=False)[0]
        img_processed = apply_preprocessing(img_bgr)
        res_b = model_b.predict(img_processed, conf=CONF_TH_B, verbose=False)[0]
        
        # 2. WBF í¬ë§· ë³€í™˜
        boxes_list, scores_list, labels_list = [], [], []
        for res in [res_a, res_b]:
            if len(res.boxes) > 0:
                boxes_list.append(res.boxes.xyxyn.cpu().numpy().tolist())
                scores_list.append(res.boxes.conf.cpu().numpy().tolist())
                labels_list.append(res.boxes.cls.cpu().numpy().astype(int).tolist())
            else:
                boxes_list.append([])
                scores_list.append([])
                labels_list.append([])

        # 3. WBF ì‹¤í–‰
        f_boxes, f_scores, f_labels = weighted_boxes_fusion(
            boxes_list, scores_list, labels_list, 
            weights=WBF_WEIGHTS,  # [1.2, 1.0] ì ìš©
            iou_thr=WBF_IOU_TH, 
            skip_box_thr=WBF_SKIP_TH      # WBF ë‚´ë¶€ì—ì„œëŠ” ë‚®ì€ ì ìˆ˜ë„ ì¼ë‹¨ í•©ì¹˜ë„ë¡ ì„¤ì •
        )

        # 4. ê²°ê³¼ ì €ì¥ ë° ì‹œê°í™”
        viz_img = img_bgr.copy()
        for box, score, label in zip(f_boxes, f_scores, f_labels):

            # [ì¶”ê°€ëœ ë¶€ë¶„] WBF ì´í›„ ìµœì¢… ì ìˆ˜ê°€ ì„ê³„ê°’(ì˜ˆ: 0.5)ë³´ë‹¤ ë‚®ìœ¼ë©´ ë²„ë¦¼
            if score < FINAL_CONF_TH:
                continue

            orig_id = yolo_to_orig.get(int(label))
            class_name = yolo_to_name.get(int(label), "Unknown")
            if orig_id is None: continue
            
            x1, y1, x2, y2 = int(box[0]*w), int(box[1]*h), int(box[2]*w), int(box[3]*h)
            
            # Submission ë°ì´í„° ì¶”ê°€
            rows.append({
                "annotation_id": ann_id,
                "image_id": image_id,
                "category_id": orig_id,
                "bbox_x": float(x1), "bbox_y": float(y1),
                "bbox_w": float(x2 - x1), "bbox_h": float(y2 - y1),
                "score": float(score)
            })
            ann_id += 1

            # ì‹œê°í™” (ë°•ìŠ¤ + í•œê¸€ ë¼ë²¨)
            cv2.rectangle(viz_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label_text = f"{class_name} {score:.2f}"
            viz_img = draw_hangeul_label(viz_img, label_text, (x1, y1 - 25))

        # ì´ë¯¸ì§€ ì €ì¥ (í•œê¸€ ê²½ë¡œ ëŒ€ì‘)
        viz_path = VIZ_DIR / f"{img_path.stem}_ensemble.jpg"
        _, res_img = cv2.imencode(".jpg", viz_img)
        res_img.tofile(str(viz_path))

    # ìµœì¢… CSV ì €ì¥
    pd.DataFrame(rows).to_csv(SUBMISSION_CSV, index=False)
    print("\n" + "="*60)
    print(f"ğŸ“Š {MODEL_NAME} ê²€ì¦ ì„±ì í‘œ")
    print("-" * 60)
    print(report_df.to_string(index=False))
    print("="*60)
    print(f"\nâœ… ì•™ìƒë¸” ì™„ë£Œ!")
    print(f"ğŸ“Š ì œì¶œ íŒŒì¼: {SUBMISSION_CSV}")
    print(f"ğŸ–¼ï¸ ì‹œê°í™” í´ë”: {VIZ_DIR}")

if __name__ == "__main__":
    main()