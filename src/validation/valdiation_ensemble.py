"""
YOLOv11 ì•™ìƒë¸” ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ (ë™ê¸°í™” ë²„ì „)

1. í‰ê°€ ë°ì´í„°ì…‹ (Evaluation Dataset):
    - ì¶œì²˜: AIHub (TS_6ë²ˆ ë°ì´í„°ì…‹)
    - ëª©ì : í•™ìŠµì— ì‚¬ìš©ë˜ì§€ ì•Šì€ ì™¸ë¶€ ë…ë¦½ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ ê²€ì¦.

2. ì£¼ìš” í‰ê°€ ì§€í‘œ:
    - Precision, Recall, F1-Score, mAP50
    - TP/FP/FN ì ˆëŒ€ ìˆ˜ì¹˜ ì‚°ì¶œ
"""

import cv2
import numpy as np
import pandas as pd
from pathlib import Path
from ultralytics import YOLO
from ensemble_boxes import weighted_boxes_fusion
from tqdm import tqdm
from datetime import datetime

# =========================
# (1) ê²½ë¡œ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° (Submissionê³¼ í†µì¼)
# =========================
MODEL_A_PATH = Path(r"E:\github\healtheat_vision\artifacts\models\yolo11s_full_train_v1_e150.pt")
MODEL_B_PATH = Path(r"E:\github\healtheat_vision\artifacts\models\yolo11s_ft_v1_enhanced.pt")

VAL_IMG_DIR = Path(r"E:\github\healtheat_vision\validation\yolo_val_ready\images")
VAL_LABEL_DIR = Path(r"E:\github\healtheat_vision\validation\yolo_val_ready\labels")
REPORT_SAVE_DIR = Path(r"E:\github\healtheat_vision\validation")
REPORT_SAVE_DIR.mkdir(parents=True, exist_ok=True)

# ì•™ìƒë¸” í•˜ì´í¼íŒŒë¼ë¯¸í„°
CONF_TH_A = 0.7      # ëª¨ë¸ AëŠ” ì—„ê²©í•˜ê²Œ (ê³ ë“ì  ìœ„ì£¼)
CONF_TH_B = 0.4      # ëª¨ë¸ BëŠ” ë„ˆê·¸ëŸ½ê²Œ (Aê°€ ë†“ì¹œ ê²ƒ ìˆ˜ì§‘)
FINAL_CONF_TH = 0.4  # WBF ì´í›„ ìµœì¢…ì ìœ¼ë¡œ ë‚¨ê¸¸ ì ìˆ˜
WBF_IOU_TH = 0.6
WBF_SKIP_TH = 0.05  # (ëª¨ë¸ Bì˜ í›„ë³´ë¥¼ ì‚´ë¦¬ê¸° ìœ„í•´)
WBF_WEIGHTS = [1.05, 1.0] # ëª¨ë¸ Aì˜ ìœ„ì¹˜ ì‹ ë¢°ë„ë¥¼ 5% ë” ë†’ê²Œ í‰ê°€
MATCH_IOU_TH = 0.5   # ê²€ì¦ ì‹œ ì •ë‹µ ì¸ì • IoU (í‘œì¤€ 0.5)

# =========================
# (2) ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =========================
def apply_preprocessing(img_bgr):
    """ëª¨ë¸ B ì „ìš© ì „ì²˜ë¦¬ (Submissionê³¼ ë™ì¼)"""
    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    img = cv2.merge((cl, a, b))
    img = cv2.cvtColor(img, cv2.COLOR_LAB2BGR)
    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
    return cv2.filter2D(img, -1, kernel)

def calculate_iou(box1, box2):
    """[x1, y1, x2, y2] í˜•ì‹ì˜ IoU ê³„ì‚°"""
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection
    return intersection / union if union > 0 else 0

# =========================
# (3) ë©”ì¸ í‰ê°€ ë¡œì§
# =========================
def main():
    print(f"ğŸš€ ì•™ìƒë¸” ê²€ì¦ ì‹œì‘ (AIHub TS_6) - A:{CONF_TH_A} / B:{CONF_TH_B}")
    
    model_a = YOLO(str(MODEL_A_PATH))
    model_b = YOLO(str(MODEL_B_PATH))
    
    img_paths = list(VAL_IMG_DIR.glob("*.jpg")) + list(VAL_IMG_DIR.glob("*.png"))
    tp, fp, fn, total_gt_count = 0, 0, 0, 0

    for img_path in tqdm(img_paths, desc="Evaluating Ensemble"):
        # 1. ì •ë‹µ(GT) ë¡œë“œ
        label_path = VAL_LABEL_DIR / f"{img_path.stem}.txt"
        gt_boxes = []
        if label_path.exists():
            with open(label_path, 'r') as f:
                for line in f.readlines():
                    cls, x, y, w, h = map(float, line.split())
                    gt_boxes.append([cls, x-w/2, y-h/2, x+w/2, y+h/2])
        total_gt_count += len(gt_boxes)

        # 2. ì´ë¯¸ì§€ ë¡œë“œ ë° ì¶”ë¡ 
        img_array = np.fromfile(str(img_path), np.uint8)
        img_bgr = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        
        res_a = model_a.predict(img_bgr, conf=CONF_TH_A, verbose=False)[0]
        img_proc = apply_preprocessing(img_bgr)
        res_b = model_b.predict(img_proc, conf=CONF_TH_B, verbose=False)[0]
        
        b_list, s_list, l_list = [], [], []
        for r in [res_a, res_b]:
            if len(r.boxes) > 0:
                b_list.append(r.boxes.xyxyn.cpu().numpy().tolist())
                s_list.append(r.boxes.conf.cpu().numpy().tolist())
                l_list.append(r.boxes.cls.cpu().numpy().astype(int).tolist())
            else:
                b_list.append([]), s_list.append([]), l_list.append([])
        
        # WBF ì‹¤í–‰
        f_b, f_s, f_l = weighted_boxes_fusion(b_list, s_list, l_list, weights=WBF_WEIGHTS, iou_thr=WBF_IOU_TH, skip_box_thr=WBF_SKIP_TH)
        
        # ìµœì¢… í•„í„°ë§
        final_p_boxes = [b for b, s in zip(f_b, f_s) if s >= FINAL_CONF_TH]
        final_p_labels = [l for l, s in zip(f_l, f_s) if s >= FINAL_CONF_TH]

        # 3. ì±„ì  (TP/FP/FN)
        matched_gt = set()
        for p_box, p_cls in zip(final_p_boxes, final_p_labels):
            match_found = False
            for i, (g_cls, g_x1, g_y1, g_x2, g_y2) in enumerate(gt_boxes):
                if i in matched_gt: continue
                if int(p_cls) == int(g_cls):
                    iou = calculate_iou(p_box, [g_x1, g_y1, g_x2, g_y2])
                    if iou >= MATCH_IOU_TH:
                        tp += 1
                        matched_gt.add(i)
                        match_found = True
                        break
            if not match_found:
                fp += 1
        fn += (len(gt_boxes) - len(matched_gt))

    # 4. ê²°ê³¼ ì‚°ì¶œ ë° ì €ì¥
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    map50 = precision * recall 

    report_data = {
        "ModelName": "Ensemble_Final", "Precision": round(precision, 4),
        "Recall": round(recall, 4), "F1-Score": round(f1, 4), "mAP50": round(map50, 4),
        "TP": tp, "FP": fp, "FN": fn, "Total_GT": total_gt_count
    }
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    pd.DataFrame([report_data]).to_csv(REPORT_SAVE_DIR / f"val_ensemble_{timestamp}.csv", index=False)
    print("\nâœ… ê²€ì¦ ì™„ë£Œ. ë³´ê³ ì„œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()