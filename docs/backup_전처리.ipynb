{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e89f82",
   "metadata": {},
   "source": [
    "# ì•Œì•½ íŒë³„ EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5768afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë…¸íŠ¸ë¶ ìƒìœ„ í´ë” ê²½ë¡œ ì¶”ê°€\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec6b193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì„í¬íŠ¸\n",
    "from src.utils import get_device, init_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc8e570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 16:00:49 [INFO] (600008572.py:4) - Using device: mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple MPS GPU detected.\n"
     ]
    }
   ],
   "source": [
    "logger = init_logger(name=\"healtheat_vision\")  # ì—¬ê¸°ì„œë§Œ í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì§€ì •\n",
    "device = get_device()\n",
    "\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ff477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-12 16:00:49 [INFO] (394718001.py:13) - ë°ì´í„° ê²½ë¡œ í™•ì¸ ì™„ë£Œ.\n",
      "2025-12-12 16:00:49 [INFO] (394718001.py:19) - Paths OK\n",
      "  - img_dir : /Users/youuchul/Documents/github/03_projects/01_HealthEat Pill Detection Model/healtheat_vision/data/train_images\n",
      "  - ann_dir : /Users/youuchul/Documents/github/03_projects/01_HealthEat Pill Detection Model/healtheat_vision/data/train_annotations\n",
      "  - ann_aihub_dir : /Users/youuchul/Documents/github/03_projects/01_HealthEat Pill Detection Model/healtheat_vision/data/aihub_downloads\n",
      "2025-12-12 16:00:49 [INFO] (394718001.py:26) - Root structure:\n",
      "  - Folders: ['test_images', 'train_annotations', 'aihub_downloads', 'eda_files', 'train_images', 'train_labels']\n",
      "  - Files  : ['.DS_Store', 'train.txt', '.gitkeep', 'missing_annotations.txt', 'val.txt']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "root = Path(\"../data\")\n",
    "img_dir = root / \"train_images\"\n",
    "ann_dir = root / \"train_annotations\"\n",
    "ann_aihub_dir = root / \"aihub_downloads\"\n",
    "\n",
    "if not img_dir.exists() or not ann_dir.exists() or not ann_aihub_dir.exists():\n",
    "    logger.error(\"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„° í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "else:\n",
    "    logger.info(\"ë°ì´í„° ê²½ë¡œ í™•ì¸ ì™„ë£Œ.\")\n",
    "\n",
    "# 2) ë£¨íŠ¸ ê²½ë¡œì˜ í´ë”/íŒŒì¼ ëª©ë¡ ë¡œê¹…\n",
    "folders = [p.name for p in root.iterdir() if p.is_dir()]\n",
    "files   = [p.name for p in root.iterdir() if p.is_file()]\n",
    "\n",
    "logger.info(\n",
    "    f\"Paths OK\\n\"\n",
    "    f\"  - img_dir : {img_dir.resolve()}\\n\"\n",
    "    f\"  - ann_dir : {ann_dir.resolve()}\\n\"\n",
    "    f\"  - ann_aihub_dir : {ann_aihub_dir.resolve()}\"\n",
    ")\n",
    "\n",
    "logger.info(\n",
    "    \"Root structure:\\n\"\n",
    "    f\"  - Folders: {folders}\\n\"\n",
    "    f\"  - Files  : {files}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a09d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì´ë¯¸ì§€ ìˆ˜(ì‹¤ì œ PNG): 651\n",
      "ì´ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ìˆ˜(JSON): 1001\n",
      "ì´ ai_hub ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ìˆ˜(JSON): 40547\n",
      "\n",
      "JSONì˜ annotations ì—”íŠ¸ë¦¬ í•©ê³„ 1001\n",
      "JSONì˜ ì´ë¯¸ì§€ ì—”íŠ¸ë¦¬ í•©ê³„: 1001\n",
      "JSONì—ì„œ ì°¸ì¡°í•˜ëŠ” ê³ ìœ  ì´ë¯¸ì§€ ìˆ˜: 369\n"
     ]
    }
   ],
   "source": [
    "# 1) ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘\n",
    "img_paths = list(img_dir.glob(\"*.png\"))\n",
    "print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜(ì‹¤ì œ PNG): {len(img_paths)}\")\n",
    "\n",
    "# 2) ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œ ìˆ˜ì§‘ (ì¬ê·€)\n",
    "ann_paths = list(ann_dir.rglob(\"*.json\"))\n",
    "print(f\"ì´ ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ìˆ˜(JSON): {len(ann_paths)}\")\n",
    "\n",
    "# 3) ai_hub ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œ ìˆ˜ì§‘\n",
    "ann_aihub_paths = list(ann_aihub_dir.rglob(\"*.json\"))\n",
    "print(f\"ì´ ai_hub ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ ìˆ˜(JSON): {len(ann_aihub_paths)}\\n\")\n",
    "\n",
    "# ë°•ìŠ¤ ìˆ˜\n",
    "total_boxes = 0\n",
    "for path in ann_paths:\n",
    "    data = json.loads(path.read_text())\n",
    "    total_boxes += len(data[\"annotations\"])\n",
    "print(\"JSONì˜ annotations ì—”íŠ¸ë¦¬ í•©ê³„\", total_boxes)\n",
    "\n",
    "# JSON ì•ˆì—ì„œ ì°¸ì¡°í•˜ëŠ” ì´ë¯¸ì§€\n",
    "total_image_entries = 0\n",
    "json_image_names = set()\n",
    "\n",
    "for path in ann_paths:\n",
    "    data = json.loads(path.read_text())\n",
    "    imgs = data[\"images\"]\n",
    "    total_image_entries += len(imgs)\n",
    "    for img_info in imgs:\n",
    "        json_image_names.add(img_info[\"file_name\"])\n",
    "\n",
    "print(\"JSONì˜ ì´ë¯¸ì§€ ì—”íŠ¸ë¦¬ í•©ê³„:\", total_image_entries)\n",
    "print(\"JSONì—ì„œ ì°¸ì¡°í•˜ëŠ” ê³ ìœ  ì´ë¯¸ì§€ ìˆ˜:\", len(json_image_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8492b4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë§¤ì¹­ëœ ì´ë¯¸ì§€-ì–´ë…¸í…Œì´ì…˜ pair ìˆ˜: 232\n",
      "ì˜ˆì‹œ key: K-001900-016548-019607-029451_0_2_0_2_70_000_200\n",
      "ì´ë¯¸ì§€ ê²½ë¡œ: ../data/train_images/K-001900-016548-019607-029451_0_2_0_2_70_000_200.png\n",
      "ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œ: ../data/train_annotations/K-001900-016548-019607-029451_json/K-019607/K-001900-016548-019607-029451_0_2_0_2_70_000_200.json\n",
      "ë§¤ì¹­ëœ ì´ë¯¸ì§€-ì–´ë…¸í…Œì´ì…˜ pair ìˆ˜: 651\n",
      "ì˜ˆì‹œ key: K-001900-010224-016551-031705_0_2_0_2_70_000_200\n",
      "ì´ë¯¸ì§€ ê²½ë¡œ: ../data/train_images/K-001900-010224-016551-031705_0_2_0_2_70_000_200.png\n",
      "ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œ: ../data/aihub_downloads/raw_extracted/K-001900-010224-016551-031705_json/K-016551/K-001900-010224-016551-031705_0_2_0_2_70_000_200.json\n"
     ]
    }
   ],
   "source": [
    "# 3) stem ê¸°ë°˜ ë§¤í•‘(dict ìƒì„±)\n",
    "img_dict = {p.stem: p for p in img_paths}\n",
    "ann_dict = {p.stem: p for p in ann_paths}\n",
    "ann_aihub_dict = {p.stem: p for p in ann_aihub_paths}\n",
    "\n",
    "# 4) ê³µí†µ key = ì •ìƒ ë§¤ì¹­ëœ pair\n",
    "common_keys = sorted(img_dict.keys() & ann_dict.keys())\n",
    "print(f\"ë§¤ì¹­ëœ ì´ë¯¸ì§€-ì–´ë…¸í…Œì´ì…˜ pair ìˆ˜: {len(common_keys)}\")\n",
    "\n",
    "example_key = common_keys[0]\n",
    "print(\"ì˜ˆì‹œ key:\", example_key)\n",
    "print(\"ì´ë¯¸ì§€ ê²½ë¡œ:\", img_dict[example_key])\n",
    "print(\"ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œ:\", ann_dict[example_key])\n",
    "\n",
    "\n",
    "common_keys_aihub = sorted(img_dict.keys() & ann_aihub_dict.keys())\n",
    "print(f\"ë§¤ì¹­ëœ ì´ë¯¸ì§€-ì–´ë…¸í…Œì´ì…˜ pair ìˆ˜: {len(common_keys_aihub)}\")\n",
    "\n",
    "example_key_aihub = common_keys_aihub[0]\n",
    "print(\"ì˜ˆì‹œ key:\", example_key_aihub)\n",
    "print(\"ì´ë¯¸ì§€ ê²½ë¡œ:\", img_dict[example_key_aihub])\n",
    "print(\"ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œ:\", ann_aihub_dict[example_key_aihub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6497217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation File: K-001900-016548-019607-029451_0_2_0_2_70_000_200.json\n",
      "\n",
      "JSON Key êµ¬ì¡°: dict_keys(['images', 'type', 'annotations', 'categories'])\n",
      "{'images': [{'file_name': 'K-001900-016548-019607-029451_0_2_0_2_70_000_200.png',\n",
      "             'width': 976,\n",
      "             'height': 1280,\n",
      "             'imgfile': 'K-001900-016548-019607-029451_0_2_0_2_70_000_200.png',\n",
      "             'drug_N': 'K-019607',\n",
      "             'drug_S': 'ì •ìƒì•Œì•½',\n",
      "             'back_color': 'ì—°íšŒìƒ‰ ë°°ê²½',\n",
      "             'drug_dir': 'ì•ë©´',\n",
      "             'light_color': 'ì£¼ë°±ìƒ‰',\n",
      "             'camera_la': 70,\n",
      "             'camera_lo': 0,\n",
      "             'size': 200,\n",
      "             'dl_idx': '19606',\n",
      "             'dl_mapping_code': 'K-019607',\n",
      "             'dl_name': 'ìŠ¤í† ê°€ì • 10mg',\n",
      "             'dl_name_en': 'Stogar Tab. 10mg',\n",
      "             'img_key': 'http://connectdi.com/design/img/drug/1MrFeLzYHjR.jpg',\n",
      "             'dl_material': 'ë¼í‘¸í‹°ë”˜',\n",
      "             'dl_material_en': 'Lafutidine',\n",
      "             'dl_custom_shape': 'ì •ì œ, ì €ì‘ì •',\n",
      "             'dl_company': 'ë³´ë ¹ì œì•½(ì£¼)',\n",
      "             'dl_company_en': 'Boryung',\n",
      "             'di_company_mf': '',\n",
      "             'di_company_mf_en': '',\n",
      "             'item_seq': 200607849,\n",
      "             'di_item_permit_date': '20060929',\n",
      "             'di_class_no': '[02320]ì†Œí™”ì„±ê¶¤ì–‘ìš©ì œ',\n",
      "             'di_etc_otc_code': 'ì „ë¬¸ì˜ì•½í’ˆ',\n",
      "             'di_edi_code': '641902670,A09305931',\n",
      "             'chart': 'í°ìƒ‰ì˜ ì›í˜• í•„ë¦„ì½”íŒ…ì •ì œ',\n",
      "             'drug_shape': 'ì›í˜•',\n",
      "             'thick': 2.7,\n",
      "             'leng_long': 6.1,\n",
      "             'leng_short': 6.1,\n",
      "             'print_front': 'FZ12',\n",
      "             'print_back': '',\n",
      "             'color_class1': 'í•˜ì–‘',\n",
      "             'color_class2': '',\n",
      "             'line_front': '',\n",
      "             'line_back': '',\n",
      "             'img_regist_ts': '20070213',\n",
      "             'form_code_name': 'í•„ë¦„ì½”íŒ…ì •',\n",
      "             'mark_code_front_anal': '',\n",
      "             'mark_code_back_anal': '',\n",
      "             'mark_code_front_img': '',\n",
      "             'mark_code_back_img': '',\n",
      "             'mark_code_front': '',\n",
      "             'mark_code_back': '',\n",
      "             'change_date': '20131013',\n",
      "             'id': 34}],\n",
      " 'type': 'instances',\n",
      " 'annotations': [{'area': 23250,\n",
      "                  'iscrowd': 0,\n",
      "                  'bbox': [657, 287, 155, 150],\n",
      "                  'category_id': 19606,\n",
      "                  'ignore': 0,\n",
      "                  'segmentation': [],\n",
      "                  'id': 127,\n",
      "                  'image_id': 34}],\n",
      " 'categories': [{'supercategory': 'pill', 'id': 19606, 'name': 'ìŠ¤í† ê°€ì • 10mg'}]}\n"
     ]
    }
   ],
   "source": [
    "# JSON êµ¬ì¡° í™•ì¸ (1ê°œë§Œ)\n",
    "sample_json = json.loads(ann_dict[example_key].read_text())\n",
    "print(f\"Annotation File: {ann_dict[example_key].name}\")\n",
    "print(\"\\nJSON Key êµ¬ì¡°:\", sample_json.keys())\n",
    "pprint.pp(sample_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09b54895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation File: K-001900-016548-019607-029451_0_2_0_2_70_000_200.json\n",
      "\n",
      "JSON Key êµ¬ì¡°: dict_keys(['images', 'type', 'annotations', 'categories'])\n",
      "{'images': [{'file_name': 'K-001900-016548-019607-029451_0_2_0_2_70_000_200.png',\n",
      "             'width': 976,\n",
      "             'height': 1280,\n",
      "             'imgfile': 'K-001900-016548-019607-029451_0_2_0_2_70_000_200.png',\n",
      "             'drug_N': 'K-019607',\n",
      "             'drug_S': 'ì •ìƒì•Œì•½',\n",
      "             'back_color': 'ì—°íšŒìƒ‰ ë°°ê²½',\n",
      "             'drug_dir': 'ì•ë©´',\n",
      "             'light_color': 'ì£¼ë°±ìƒ‰',\n",
      "             'camera_la': 70,\n",
      "             'camera_lo': 0,\n",
      "             'size': 200,\n",
      "             'dl_idx': '19606',\n",
      "             'dl_mapping_code': 'K-019607',\n",
      "             'dl_name': 'ìŠ¤í† ê°€ì • 10mg',\n",
      "             'dl_name_en': 'Stogar Tab. 10mg',\n",
      "             'img_key': 'http://connectdi.com/design/img/drug/1MrFeLzYHjR.jpg',\n",
      "             'dl_material': 'ë¼í‘¸í‹°ë”˜',\n",
      "             'dl_material_en': 'Lafutidine',\n",
      "             'dl_custom_shape': 'ì •ì œ, ì €ì‘ì •',\n",
      "             'dl_company': 'ë³´ë ¹ì œì•½(ì£¼)',\n",
      "             'dl_company_en': 'Boryung',\n",
      "             'di_company_mf': '',\n",
      "             'di_company_mf_en': '',\n",
      "             'item_seq': 200607849,\n",
      "             'di_item_permit_date': '20060929',\n",
      "             'di_class_no': '[02320]ì†Œí™”ì„±ê¶¤ì–‘ìš©ì œ',\n",
      "             'di_etc_otc_code': 'ì „ë¬¸ì˜ì•½í’ˆ',\n",
      "             'di_edi_code': '641902670,A09305931',\n",
      "             'chart': 'í°ìƒ‰ì˜ ì›í˜• í•„ë¦„ì½”íŒ…ì •ì œ',\n",
      "             'drug_shape': 'ì›í˜•',\n",
      "             'thick': 2.7,\n",
      "             'leng_long': 6.1,\n",
      "             'leng_short': 6.1,\n",
      "             'print_front': 'FZ12',\n",
      "             'print_back': '',\n",
      "             'color_class1': 'í•˜ì–‘',\n",
      "             'color_class2': '',\n",
      "             'line_front': '',\n",
      "             'line_back': '',\n",
      "             'img_regist_ts': '20070213',\n",
      "             'form_code_name': 'í•„ë¦„ì½”íŒ…ì •',\n",
      "             'mark_code_front_anal': '',\n",
      "             'mark_code_back_anal': '',\n",
      "             'mark_code_front_img': '',\n",
      "             'mark_code_back_img': '',\n",
      "             'mark_code_front': '',\n",
      "             'mark_code_back': '',\n",
      "             'change_date': '20131013',\n",
      "             'id': 1}],\n",
      " 'type': 'instances',\n",
      " 'annotations': [{'area': 23250,\n",
      "                  'iscrowd': 0,\n",
      "                  'bbox': [657, 287, 155, 150],\n",
      "                  'category_id': 1,\n",
      "                  'ignore': 0,\n",
      "                  'segmentation': [],\n",
      "                  'id': 1,\n",
      "                  'image_id': 1}],\n",
      " 'categories': [{'supercategory': 'pill', 'id': 1, 'name': 'Drug'}]}\n"
     ]
    }
   ],
   "source": [
    "# aihub_JSON êµ¬ì¡° í™•ì¸ (1ê°œë§Œ)\n",
    "sample_json = json.loads(ann_aihub_dict[example_key].read_text())\n",
    "print(f\"Annotation File: {ann_aihub_dict[example_key].name}\")\n",
    "print(\"\\nJSON Key êµ¬ì¡°:\", sample_json.keys())\n",
    "pprint.pp(sample_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6eb101c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë§¤ì¹­ëœ ì´ë¯¸ì§€-aihug ì–´ë…¸í…Œì´ì…˜ pair ìˆ˜: 651\n"
     ]
    }
   ],
   "source": [
    "# img â†” aihub annotation ì´ ë‘˜ ë‹¤ ì¡´ì¬í•˜ëŠ” key\n",
    "common_keys_aihub = sorted(img_dict.keys() & ann_aihub_dict.keys())\n",
    "print(f\"ë§¤ì¹­ëœ ì´ë¯¸ì§€-aihug ì–´ë…¸í…Œì´ì…˜ pair ìˆ˜: {len(common_keys_aihub)}\")\n",
    "\n",
    "# ë§¤ì¹­ëœ aihub annotation dict\n",
    "matched_ann_aihub_dict = {\n",
    "    k: ann_aihub_dict[k]\n",
    "    for k in common_keys_aihub\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03cb3feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: K-001900-010224-016551-031705_0_2_0_2_70_000_200\n",
      "image: ../data/train_images/K-001900-010224-016551-031705_0_2_0_2_70_000_200.png\n",
      "aihug ann: ../data/aihub_downloads/raw_extracted/K-001900-010224-016551-031705_json/K-016551/K-001900-010224-016551-031705_0_2_0_2_70_000_200.json\n"
     ]
    }
   ],
   "source": [
    "k = common_keys_aihub[0]\n",
    "print(\"key:\", k)\n",
    "print(\"image:\", img_dict[k])\n",
    "print(\"aihug ann:\", matched_ann_aihub_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d799e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¤‘ë³µ stem (images): 0\n",
      "ì¤‘ë³µ stem (aihub json): 10506\n",
      "\n",
      "ì˜ˆì‹œ ì¤‘ë³µ aihub stem: K-005391-018357-021325_0_2_0_2_90_000_200 ê°œìˆ˜: 3\n",
      " - ../data/aihub_downloads/raw_extracted/K-005391-018357-021325_json/K-018357/K-005391-018357-021325_0_2_0_2_90_000_200.json\n",
      " - ../data/aihub_downloads/raw_extracted/K-005391-018357-021325_json/K-005391/K-005391-018357-021325_0_2_0_2_90_000_200.json\n",
      " - ../data/aihub_downloads/raw_extracted/K-005391-018357-021325_json/K-021325/K-005391-018357-021325_0_2_0_2_90_000_200.json\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "# 1) aihub / img stem ì¤‘ë³µ ì²´í¬\n",
    "img_stem_cnt = Counter([p.stem for p in img_paths])\n",
    "aih_stem_cnt = Counter([p.stem for p in ann_aihub_paths])\n",
    "\n",
    "dup_img  = [k for k,v in img_stem_cnt.items() if v > 1]\n",
    "dup_aih  = [k for k,v in aih_stem_cnt.items() if v > 1]\n",
    "\n",
    "print(\"ì¤‘ë³µ stem (images):\", len(dup_img))\n",
    "print(\"ì¤‘ë³µ stem (aihub json):\", len(dup_aih))\n",
    "\n",
    "if dup_aih:\n",
    "    k = dup_aih[0]\n",
    "    print(\"\\nì˜ˆì‹œ ì¤‘ë³µ aihub stem:\", k, \"ê°œìˆ˜:\", aih_stem_cnt[k])\n",
    "    for p in [x for x in ann_aihub_paths if x.stem == k][:10]:\n",
    "        print(\" -\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0574e90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³µì‚¬ ëŒ€ìƒ ìµœìƒìœ„ í´ë” ìˆ˜: 1\n",
      "í´ë” ë³µì‚¬ ì™„ë£Œ\n",
      "ë³µì‚¬ëœ í´ë”: 0\n",
      "ì´ë¯¸ ì¡´ì¬í•´ ìŠ¤í‚µ: 1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "src_root = Path(ann_aihub_dir)\n",
    "dst_root = Path(\n",
    "    \"/Users/youuchul/Documents/github/03_projects/01_HealthEat Pill Detection Model/healtheat_vision/data/aihub_downloads/raw_matched\"\n",
    ")\n",
    "\n",
    "dst_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ë§¤ì¹­ëœ json ê²½ë¡œë“¤\n",
    "src_json_paths = [ann_aihub_dict[k] for k in common_keys_aihub]\n",
    "\n",
    "# aihub_downloads ê¸°ì¤€ 'ìµœìƒìœ„ í´ë”' set\n",
    "top_level_dirs = set()\n",
    "\n",
    "for p in src_json_paths:\n",
    "    rel = p.relative_to(src_root)\n",
    "    top_dir = rel.parts[0]   # ğŸ‘ˆ í•µì‹¬\n",
    "    top_level_dirs.add(top_dir)\n",
    "\n",
    "print(\"ë³µì‚¬ ëŒ€ìƒ ìµœìƒìœ„ í´ë” ìˆ˜:\", len(top_level_dirs))\n",
    "\n",
    "copied = 0\n",
    "skipped = 0\n",
    "\n",
    "for d in sorted(top_level_dirs):\n",
    "    src_dir = src_root / d\n",
    "    dst_dir = dst_root / d\n",
    "\n",
    "    if dst_dir.exists():\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    shutil.copytree(src_dir, dst_dir)\n",
    "    copied += 1\n",
    "\n",
    "print(\"í´ë” ë³µì‚¬ ì™„ë£Œ\")\n",
    "print(\"ë³µì‚¬ëœ í´ë”:\", copied)\n",
    "print(\"ì´ë¯¸ ì¡´ì¬í•´ ìŠ¤í‚µ:\", skipped)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "259bfd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ìš”ì•½(aihug json + ë§¤ì¹­ pair ê¸°ì¤€) ===\n",
      "ê³ ìœ  dl_idx ìˆ˜: 32\n",
      "ê³ ìœ  dl_name ìˆ˜: 32\n",
      "ê³ ìœ  (dl_idx, dl_name) ìŒ ìˆ˜: 32\n",
      "images ëˆ„ë½/í•„ë“œ ëˆ„ë½ ê±´ìˆ˜(ëŒ€ëµ): 0\n",
      "imagesê°€ 2ê°œ ì´ìƒì¸ json ìˆ˜: 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# aihub ê¸°ì¤€ìœ¼ë¡œ \"ë§¤ì¹­ëœ pair\"ë§Œ ì§‘ê³„ (ì›í•˜ë©´ ì „ì²´ë„ ê°€ëŠ¥)\n",
    "keys_to_use = common_keys_aihub   # âœ… ì´ê²Œ í¬ì¸íŠ¸ (aihub ê¸°ì¤€)\n",
    "\n",
    "dl_idx_counter = Counter()\n",
    "dl_name_counter = Counter()\n",
    "pair_counter = Counter()          # (dl_idx, dl_name) ìŒ\n",
    "dl_idx_to_name = {}              # dl_idx -> dl_name (ëŒ€í‘œê°’)\n",
    "\n",
    "missing = 0\n",
    "multi_image_json = 0\n",
    "\n",
    "for key in keys_to_use:\n",
    "    p = ann_aihub_dict[key]       # âœ… aihub json ì‚¬ìš©\n",
    "    data = json.loads(p.read_text())\n",
    "\n",
    "    imgs = data.get(\"images\", [])\n",
    "    if not imgs:\n",
    "        missing += 1\n",
    "        continue\n",
    "\n",
    "    if len(imgs) > 1:\n",
    "        multi_image_json += 1\n",
    "\n",
    "    # ë³´í†µ 1ê°œì§€ë§Œ, ì•ˆì „í•˜ê²Œ images ì „ì²´ ìˆœíšŒ\n",
    "    for img in imgs:\n",
    "        dl_idx  = img.get(\"dl_idx\")\n",
    "        dl_name = img.get(\"dl_name\")\n",
    "\n",
    "        if not dl_idx or not dl_name:\n",
    "            missing += 1\n",
    "            continue\n",
    "\n",
    "        dl_idx_counter[dl_idx] += 1\n",
    "        dl_name_counter[dl_name] += 1\n",
    "        pair_counter[(dl_idx, dl_name)] += 1\n",
    "\n",
    "        # ê°™ì€ dl_idxê°€ ë‹¤ë¥¸ nameì„ ê°–ëŠ” ì¼€ì´ìŠ¤ ì²´í¬ìš©ìœ¼ë¡œë„ ì“¸ ìˆ˜ ìˆìŒ\n",
    "        dl_idx_to_name.setdefault(dl_idx, dl_name)\n",
    "\n",
    "print(\"=== ìš”ì•½(aihug json + ë§¤ì¹­ pair ê¸°ì¤€) ===\")\n",
    "print(\"ê³ ìœ  dl_idx ìˆ˜:\", len(dl_idx_counter))\n",
    "print(\"ê³ ìœ  dl_name ìˆ˜:\", len(dl_name_counter))\n",
    "print(\"ê³ ìœ  (dl_idx, dl_name) ìŒ ìˆ˜:\", len(pair_counter))\n",
    "print(\"images ëˆ„ë½/í•„ë“œ ëˆ„ë½ ê±´ìˆ˜(ëŒ€ëµ):\", missing)\n",
    "print(\"imagesê°€ 2ê°œ ì´ìƒì¸ json ìˆ˜:\", multi_image_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f63b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# dl_idx / dl_name ì¹´ìš´íŠ¸\n",
    "dl_idx_counter = Counter()\n",
    "dl_idx_to_name = {}\n",
    "\n",
    "for p in aihub_jsons:\n",
    "    with open(p, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # images ë©”íƒ€ë°ì´í„° ê¸°ì¤€\n",
    "    for img in data.get(\"images\", []):\n",
    "        dl_idx  = img.get(\"dl_idx\")\n",
    "        dl_name = img.get(\"dl_name\")\n",
    "\n",
    "        if dl_idx is None or dl_name is None:\n",
    "            continue\n",
    "\n",
    "        dl_idx_counter[dl_idx] += 1\n",
    "        dl_idx_to_name[dl_idx] = dl_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8f3bc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³ ìœ  dl_idx ê°œìˆ˜: 56\n",
      "ê³ ìœ  dl_idx ì¼ë¶€: ['3350', '16231', '33879', '41767', '35205', '29666', '13899', '20013', '16687', '16547', '1899', '29450', '19606', '22073', '3831', '27925', '21770', '36636', '18146', '16261']\n"
     ]
    }
   ],
   "source": [
    "print(f\"ê³ ìœ  dl_idx ê°œìˆ˜: {len(dl_idx_counter)}\")\n",
    "print(\"ê³ ìœ  dl_idx ì¼ë¶€:\", list(dl_idx_counter.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# ======================\n",
    "# dl_idx / dl_name ì§‘ê³„\n",
    "# ======================\n",
    "\n",
    "dl_idx_counter  = Counter()\n",
    "dl_name_counter = Counter()\n",
    "pair_counter    = Counter()  # (id, name) ìŒ ê¸°ì¤€\n",
    "\n",
    "for key in common_keys:\n",
    "    ann_path = ann_dict[key]\n",
    "    data = json.loads(ann_path.read_text())\n",
    "\n",
    "    # êµ¬ì¡°ìƒ imagesëŠ” ë¦¬ìŠ¤íŠ¸ì§€ë§Œ ë³´í†µ 1ê°œ\n",
    "    img_info = data[\"images\"][0]\n",
    "\n",
    "    dl_idx  = img_info.get(\"dl_idx\")\n",
    "    dl_name = img_info.get(\"dl_name\")\n",
    "\n",
    "    if dl_idx is None or dl_name is None:\n",
    "        continue\n",
    "\n",
    "    dl_idx_counter[dl_idx] += 1\n",
    "    dl_name_counter[dl_name] += 1\n",
    "    pair_counter[(dl_idx, dl_name)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d597b9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ìš”ì•½ ===\n",
      "ê³ ìœ  dl_idx ìˆ˜ : 25\n",
      "ê³ ìœ  dl_name ìˆ˜: 25\n",
      "ê³ ìœ  (dl_idx, dl_name) ìŒ ìˆ˜: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"=== ìš”ì•½ ===\")\n",
    "print(\"ê³ ìœ  dl_idx ìˆ˜ :\", len(dl_idx_counter))\n",
    "print(\"ê³ ìœ  dl_name ìˆ˜:\", len(dl_name_counter))\n",
    "print(\"ê³ ìœ  (dl_idx, dl_name) ìŒ ìˆ˜:\", len(pair_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b80007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê³ ìœ  í´ë˜ìŠ¤ ê°œìˆ˜: 56\n",
      "ê³ ìœ  category_id ì¼ë¶€: [1899, 2482, 3350, 3482, 3543, 3742, 3831, 4542, 12080, 12246, 12777, 13394, 13899, 16231, 16261, 16547, 16550, 16687, 18146, 18356]\n",
      "   category_id          class_name\n",
      "0         1899          ë³´ë ¹ë¶€ìŠ¤íŒŒì • 5mg\n",
      "1         2482         ë®¤í…Œë€ìº¡ìŠ 100mg\n",
      "2         3350         ì¼ì–‘í•˜ì´íŠ¸ë¦°ì • 2mg\n",
      "3         3482  ê¸°ë„¥ì‹ ì—í”„ì •(ì€í–‰ì—½ì—‘ìŠ¤)(ìˆ˜ì¶œìš©)\n",
      "4         3543   ë¬´ì½”ìŠ¤íƒ€ì •(ë ˆë°”ë¯¸í”¼ë“œ)(ë¹„ë§¤í’ˆ)\n",
      "   category_id          class_name  count\n",
      "0         3350         ì¼ì–‘í•˜ì´íŠ¸ë¦°ì • 2mg    240\n",
      "1         3482  ê¸°ë„¥ì‹ ì—í”„ì •(ì€í–‰ì—½ì—‘ìŠ¤)(ìˆ˜ì¶œìš©)     45\n",
      "2        35205        ì•„í† ì ¯ì • 10/40mg     40\n",
      "3        16261          í¬ë ˆìŠ¤í† ì • 20mg     31\n",
      "4        20237          í”Œë¼ë¹…ìŠ¤ì • 75mg     29\n",
      "[ì™„ë£Œ] ê³ ìœ  í´ë˜ìŠ¤(ID+ì´ë¦„) ë¦¬ìŠ¤íŠ¸ CSV â†’ annotation_unique_classes_with_id.csv\n",
      "[ì™„ë£Œ] í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸(ID+ì´ë¦„+count) CSV â†’ annotation_class_counts_with_id.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# [A] ì–´ë…¸í…Œì´ì…˜ ì „ì²´ì—ì„œ ë“±ì¥í•˜ëŠ” ê³ ìœ  í´ë˜ìŠ¤ (ID + ì´ë¦„) ë¦¬ìŠ¤íŠ¸ + ì¹´ìš´íŠ¸\n",
    "# ============================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "root    = \"../data\"\n",
    "ann_dir = os.path.join(root, \"train_annotations\")\n",
    "\n",
    "# ëª¨ë“  json íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "ann_paths = glob.glob(os.path.join(ann_dir, \"**\", \"*.json\"), recursive=True)\n",
    "\n",
    "# category_id -> name ë§¤í•‘\n",
    "category_id_to_name = {}\n",
    "# í´ë˜ìŠ¤ ì¹´ìš´íŠ¸ëŠ” \"ID\" ê¸°ì¤€ìœ¼ë¡œ ìŒ“ëŠ”ë‹¤\n",
    "class_counter = Counter()\n",
    "\n",
    "for p in ann_paths:\n",
    "    with open(p, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # categories ì—ì„œ id -> name ë§¤í•‘ ê°±ì‹ \n",
    "    for cat in data[\"categories\"]:\n",
    "        category_id_to_name[cat[\"id\"]] = cat[\"name\"]\n",
    "\n",
    "    # annotations ê¸°ì¤€ìœ¼ë¡œ category_id ì¹´ìš´íŠ¸\n",
    "    for ann in data[\"annotations\"]:\n",
    "        cid = ann[\"category_id\"]\n",
    "        class_counter[cid] += 1\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# [B] ê³ ìœ  í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ID + ì´ë¦„) ì¶”ì¶œ\n",
    "# ============================================\n",
    "\n",
    "unique_category_ids = sorted(class_counter.keys())\n",
    "num_unique_classes  = len(unique_category_ids)\n",
    "\n",
    "print(f\"ê³ ìœ  í´ë˜ìŠ¤ ê°œìˆ˜: {num_unique_classes}\")\n",
    "print(\"ê³ ìœ  category_id ì¼ë¶€:\", unique_category_ids[:20])\n",
    "\n",
    "# id + name ë§¤í•‘ ë¦¬ìŠ¤íŠ¸\n",
    "unique_classes = [\n",
    "    {\n",
    "        \"category_id\": cid,\n",
    "        \"class_name\": category_id_to_name.get(cid, f\"id_{cid}\")\n",
    "    }\n",
    "    for cid in unique_category_ids\n",
    "]\n",
    "\n",
    "df_unique_classes = pd.DataFrame(unique_classes)\n",
    "print(df_unique_classes.head())\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# [C] í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸ DataFrame (ID + ì´ë¦„ + count)\n",
    "# ============================================\n",
    "\n",
    "rows = []\n",
    "for cid, cnt in class_counter.items():\n",
    "    rows.append({\n",
    "        \"category_id\": cid,\n",
    "        \"class_name\": category_id_to_name.get(cid, f\"id_{cid}\"),\n",
    "        \"count\": cnt,\n",
    "    })\n",
    "\n",
    "df_class_counts = (\n",
    "    pd.DataFrame(rows)\n",
    "    .sort_values(\"count\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(df_class_counts.head())\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# [D] CSVë¡œ ì €ì¥\n",
    "# ============================================\n",
    "\n",
    "# csv_unique_path = \"annotation_unique_classes_with_id.csv\"\n",
    "# csv_count_path  = \"annotation_class_counts_with_id.csv\"\n",
    "\n",
    "# # (1) ê³ ìœ  í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ (ID + ì´ë¦„)\n",
    "# df_unique_classes.to_csv(\n",
    "#     csv_unique_path, index=False, encoding=\"utf-8-sig\"\n",
    "# )\n",
    "\n",
    "# # (2) í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸ (ID + ì´ë¦„ + count)\n",
    "# df_class_counts.to_csv(\n",
    "#     csv_count_path, index=False, encoding=\"utf-8-sig\"\n",
    "# )\n",
    "\n",
    "# print(f\"[ì™„ë£Œ] ê³ ìœ  í´ë˜ìŠ¤(ID+ì´ë¦„) ë¦¬ìŠ¤íŠ¸ CSV â†’ {csv_unique_path}\")\n",
    "# print(f\"[ì™„ë£Œ] í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸(ID+ì´ë¦„+count) CSV â†’ {csv_count_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dd67c33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_to_anns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m class_counts = Counter()\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m common_keys:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m \u001b[43mimage_to_anns\u001b[49m[key]:\n\u001b[32m      5\u001b[39m         cid = ann[\u001b[33m\"\u001b[39m\u001b[33mcategory_id\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m         cls_name = category_id_to_name.get(cid, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mid_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'image_to_anns' is not defined"
     ]
    }
   ],
   "source": [
    "class_counts = Counter()\n",
    "\n",
    "for key in common_keys:\n",
    "    for ann in image_to_anns[key]:\n",
    "        cid = ann[\"category_id\"]\n",
    "        cls_name = category_id_to_name.get(cid, f\"id_{cid}\")\n",
    "        class_counts[cls_name] += 1\n",
    "\n",
    "print(\"í´ë˜ìŠ¤ ê°œìˆ˜:\", len(class_counts))\n",
    "for cls, cnt in class_counts.most_common(30):\n",
    "    print(f\"{cls:30s} : {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0e519",
   "metadata": {},
   "source": [
    "## ì–´ë…¸í…Œì´ì…˜ ê¸°ì¤€ ë°ì´í„° í”„ë ˆì„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
